from argparse import ArgumentParser
import codecs
import csv
import logging
import math
import os
import random
import sys

from datasets import Dataset
import numpy as np
from transformers import pipeline
from transformers.pipelines.pt_utils import KeyDataset
from tqdm import tqdm
import torch

logic_inference_logger = logging.getLogger(__name__)
RANDOM_SEED: int = 42


def sample_to_str(en_text: str, ru_text: str) -> str:
    checked_llm_prediction = ' '.join(ru_text.strip().split())
    context = ' '.join(en_text.strip().split())
    united_prompt = 'The verified system\'s task is a machine translation.'
    united_prompt += ' The sentence generated by the verified system: '
    united_prompt += checked_llm_prediction
    if united_prompt[-1].isalnum():
        united_prompt += '.'
    united_prompt += f' The generation context: {context}'
    if united_prompt[-1].isalnum():
        united_prompt += '.'
    return united_prompt


def main():
    random.seed(RANDOM_SEED)
    torch.manual_seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)

    if not torch.cuda.is_available():
        err_msg = 'CUDA is not available!'
        logic_inference_logger.error(err_msg)
        raise ValueError(err_msg)
    device = torch.device('cuda')
    torch.cuda.manual_seed(RANDOM_SEED)

    parser = ArgumentParser()
    parser.add_argument('-i', '--input', dest='input_name', type=str, required=True,
                        help='The input name of LogicInference_OA_ru dataset.')
    parser.add_argument('-o', '--output', dest='output_name', type=str, required=True,
                        help='The output name of LogicInference_OA_ru dataset with '
                             'estimated probabilities of hallucinations.')
    parser.add_argument('-m', '--model', dest='model_name', type=str, required=True,
                        help='The path to hallucination detector.')
    parser.add_argument('--batch', dest='minibatch_size', type=int, required=False, default=16,
                        help='The mini-batch size.')
    args = parser.parse_args()

    source_dataset_path = os.path.normpath(args.input_name)
    if not os.path.isdir(source_dataset_path):
        err_msg = f'The directory "{source_dataset_path}" does not exist!'
        logic_inference_logger.error(err_msg)
        raise IOError(err_msg)
    source_dataset_fname = os.path.join(source_dataset_path, 'train.csv')
    if not os.path.isfile(source_dataset_fname):
        err_msg = f'The file "{source_dataset_fname}" does not exist!'
        logic_inference_logger.error(err_msg)
        raise IOError(err_msg)

    destination_dataset_path = os.path.normpath(args.output_name)
    if not os.path.isdir(destination_dataset_path):
        err_msg = f'The directory "{destination_dataset_path}" does not exist!'
        logic_inference_logger.error(err_msg)
        raise IOError(err_msg)
    if os.path.basename(source_dataset_path) == os.path.basename(destination_dataset_path):
        err_msg = f'The destination dataset path is equal to the source one!'
        logic_inference_logger.error(err_msg)
        raise IOError(err_msg)

    destination_dataset_fname = os.path.join(destination_dataset_path, 'train.csv')

    model_name = os.path.normpath(args.model_name)
    if not os.path.isdir(model_name):
        err_msg = f'The directory "{model_name}" does not exist!'
        logic_inference_logger.error(err_msg)
        raise IOError(err_msg)

    hallucination_detector = pipeline(
        task='text-classification',
        model=model_name,
        framework='pt', trust_remote_code=True, device='cuda', torch_dtype=torch.float32
    )

    true_header = ['INSTRUCTION_EN', 'RESPONSE_EN', 'INSTRUCTION_RU', 'RESPONSE_RU', 'TRANSLATION_SCORE']
    with codecs.open(source_dataset_fname, mode='r', encoding='utf-8', errors='ignore') as fp:
        data_reader = csv.reader(fp, delimiter=',', quotechar='"')
        source_samples = list(filter(lambda it: len(it) > 0, data_reader))
        if len(source_samples) == 0:
            err_msg = f'The file "{source_dataset_fname}" is empty!'
            logic_inference_logger.error(err_msg)
            raise IOError(err_msg)
        if source_samples[0] != true_header:
            err_msg = (f'The file "{source_dataset_fname}" has a wrong header! '
                       f'Expected {true_header}, got {source_samples[0]}.')
            logic_inference_logger.error(err_msg)
            raise IOError(err_msg)
        if len(source_samples) < 2:
            err_msg = f'The file "{source_dataset_fname}" is empty!'
            logic_inference_logger.error(err_msg)
            raise IOError(err_msg)
        source_samples_without_header = source_samples[1:]
    del source_samples

    input_texts = []
    for instruction_en, response_en, instruction_ru, response_ru, _ in source_samples_without_header:
        input_texts += [
            sample_to_str(en_text=instruction_en, ru_text=instruction_ru),
            sample_to_str(en_text=response_en, ru_text=response_ru)
        ]
    input_dataset = Dataset.from_dict({'text': input_texts})
    del input_texts

    probabilities = []
    for out in tqdm(hallucination_detector(KeyDataset(input_dataset, 'text'), batch_size=args.minibatch_size,
                                           padding='longest'), total=len(input_dataset)):
        if out['label'] == 'Hallucination':
            hallucination_probability = out['score']
        else:
            hallucination_probability = 1.0 - out['score']
        probabilities.append(hallucination_probability)

    with codecs.open(destination_dataset_fname, mode='w', encoding='utf-8', buffering=0) as fp:
        data_writer = csv.writer(fp, delimiter=',', quotechar='"')
        data_writer.writerow(true_header + ['p(Hallucination)'])
        for idx, val in enumerate(source_samples_without_header):
            proba = max(probabilities[idx * 2], probabilities[idx * 2 + 1])
            data_writer.writerow([val[0], val[1], val[2], val[3], str(round(val[4], 6)), str(round(proba, 6))])


if __name__ == '__main__':
    logic_inference_logger.setLevel(logging.INFO)
    fmt_str = '%(filename)s[LINE:%(lineno)d]# %(levelname)-8s ' \
              '[%(asctime)s]  %(message)s'
    formatter = logging.Formatter(fmt_str)
    stdout_handler = logging.StreamHandler(sys.stdout)
    stdout_handler.setFormatter(formatter)
    logic_inference_logger.addHandler(stdout_handler)
    file_handler = logging.FileHandler('logic_inference_hallucination.log')
    file_handler.setFormatter(formatter)
    logic_inference_logger.addHandler(file_handler)
    main()
